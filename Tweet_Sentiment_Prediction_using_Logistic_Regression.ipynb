{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Sentiment Prediction using Logistic Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTTy1-9LQPm9"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_DJ0pJGQ4fx"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEjUj2PIUvNI",
        "outputId": "9558453a-68c6-4e9d-f6f4-19a09d72912d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06_r7L20nQIo"
      },
      "source": [
        "# Function for preprocessing the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJVU9stRE30"
      },
      "source": [
        "def process_tweet(tweet):\n",
        "  ps = PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "  tweet = re.sub(r'\\$\\w*','',tweet)\n",
        "  tweet = re.sub(r'^RT[\\s]+','',tweet)\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*','',tweet)\n",
        "  tweet = re.sub(r'#','',tweet)\n",
        "\n",
        "  tokenizer = TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweets_clean = []\n",
        "  for word in tweet_tokens:\n",
        "    if(word not in stopwords_english and word not in string.punctuation):\n",
        "      stem_word = ps.stem(word)\n",
        "      tweets_clean.append(stem_word)\n",
        "  return tweets_clean"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PylRrzrNnX4s"
      },
      "source": [
        "# Function for building frequence dict for tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3EG5H06UruV"
      },
      "source": [
        "def build_freqs(tweets,ys):\n",
        "  yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "  freqs = {}\n",
        "  for y,tweet in zip(yslist,tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word,y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair]+=1\n",
        "      else:\n",
        "        freqs[pair]=1\n",
        "  return freqs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LIzF9lMnfTQ"
      },
      "source": [
        "#Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7T-ooRaUsP-"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JrpKa3uXf7C"
      },
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIkDF9ygXhCm"
      },
      "source": [
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BoMd4ZYoti"
      },
      "source": [
        "train_y = np.append(np.ones((len(train_pos),1)),np.zeros((len(train_neg),1)),axis = 0)\n",
        "test_y = np.append(np.ones((len(test_pos),1)),np.zeros((len(test_neg),1)),axis = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME4R1yAlYpl5",
        "outputId": "5eb69464-349f-4b76-e8f3-09a3efc9b0fe"
      },
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fVNL5GdZdvp",
        "outputId": "713aaa93-108d-420b-845f-67b9247da149"
      },
      "source": [
        "freqs = build_freqs(train_x,train_y)\n",
        "\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 11346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j4F1fC3Zq2d",
        "outputId": "49eed0d8-3b78-436e-bdad-efdef5198391"
      },
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is an example of a positive tweet: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NQDWYwjnjY5"
      },
      "source": [
        "# Creating functions for doing Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXAx0t0nadW-"
      },
      "source": [
        "def sigmoid(z):\n",
        "  h = 1/(1+np.exp(-z))\n",
        "\n",
        "  return h"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBryi36PdMkE"
      },
      "source": [
        "def gradientDescent(x,y,theta,alpha,num_iters):\n",
        "  m =  x.shape[0]\n",
        "\n",
        "  for i in range(0,num_iters):\n",
        "    z = np.dot(x,theta)\n",
        "    h = sigmoid(z)\n",
        "\n",
        "    j = (-1./m)*(np.dot(y.transpose(),np.log(h))+np.dot((1-y).transpose(),np.log(1-h)))\n",
        "\n",
        "    theta = theta-(alpha/m)*np.dot(x.transpose(),(h-y))\n",
        "\n",
        "  j = float(j)\n",
        "\n",
        "  return j,theta"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-beCr-Nnpc3"
      },
      "source": [
        "# Extracting the features for doing LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYvhPyfJhOps"
      },
      "source": [
        "def extract_features(tweet,freqs):\n",
        "  word_l = process_tweet(tweet)\n",
        "\n",
        "  x = np.zeros((1,3))\n",
        "\n",
        "  x[0,0] =1 \n",
        "\n",
        "  for word in word_l:\n",
        "    x[0,1] +=  freqs.get((word,1.0),0)\n",
        "\n",
        "    x[0,2] += freqs.get((word,0.0),0)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DozfXEQEiWrG"
      },
      "source": [
        "X = np.zeros((len(train_x),3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "Y = train_y"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_JpcSBgn2z0"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUG_nj8jiaMl",
        "outputId": "57f35f4c-75b3-4e04-a816-93dcf8f5c6b6"
      },
      "source": [
        "j,theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {j:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost after training is 0.24216529.\n",
            "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQWbozHpn6-p"
      },
      "source": [
        "# Function for predicting the sentiment score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ywh3cCilfY"
      },
      "source": [
        "def predict_tweet(tweet, freqs,theta):\n",
        "  x = extract_features(tweet,freqs)\n",
        "  y_pred = sigmoid(np.dot(x,theta))\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPa9IH_cmNEF",
        "outputId": "50918698-5088-4981-b976-841666218261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am happy -> 0.518580\n",
            "I am bad -> 0.494339\n",
            "this movie should have been great. -> 0.515331\n",
            "great -> 0.515464\n",
            "great great -> 0.530898\n",
            "great great great -> 0.546273\n",
            "great great great great -> 0.561561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcd3eD0goAFS"
      },
      "source": [
        "# Final function for providing the sentiment prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm_6A7A6mPUE"
      },
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    y_hat = []\n",
        "    \n",
        "    for tweet in test_x:\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        \n",
        "        if y_pred > 0.5:\n",
        "            y_hat.append(1)\n",
        "        else: \n",
        "            y_hat.append(0)   \n",
        "\n",
        "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
        "\n",
        "    return accuracy\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2bwBmK-m2kD",
        "outputId": "44060522-2986-40da-f1d3-6ed43a2d3cff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}